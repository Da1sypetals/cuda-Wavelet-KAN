{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - a e^{- \\frac{y^{2}}{2}} \\sin{\\left(a y \\right)} - y e^{- \\frac{y^{2}}{2}} \\cos{\\left(a y \\right)}$"
      ],
      "text/plain": [
       "-a*exp(-y**2/2)*sin(a*y) - y*exp(-y**2/2)*cos(a*y)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import symbols, cos, exp, diff\n",
    "\n",
    "# Defining symbols\n",
    "y, a = symbols('y a')\n",
    "\n",
    "# Defining the function\n",
    "f = cos(a*y) * exp(-y**2 / 2)\n",
    "\n",
    "# Finding the derivative with respect to y\n",
    "derivative_f = diff(f, y)\n",
    "\n",
    "# Display the derivative\n",
    "derivative_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is a sample code for the simulations of the paper:\n",
    "Bozorgasl, Zavareh and Chen, Hao, Wav-KAN: Wavelet Kolmogorov-Arnold Networks (May, 2024)\n",
    "\n",
    "https://arxiv.org/abs/2405.12832\n",
    "and also available at:\n",
    "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835325\n",
    "We used efficient KAN notation and some part of the code:https://github.com/Blealtan/efficient-kan\n",
    "\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "class KANLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, wavelet_type='mexican_hat'):\n",
    "        super(KANLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.wavelet_type = wavelet_type\n",
    "\n",
    "        # Parameters for wavelet transformation\n",
    "        self.scale = nn.Parameter(torch.ones(out_features, in_features))\n",
    "        self.translation = nn.Parameter(torch.zeros(out_features, in_features))\n",
    "\n",
    "        # Linear weights for combining outputs\n",
    "        #self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight1 = nn.Parameter(torch.Tensor(out_features, in_features)) #not used; you may like to use it for wieghting base activation and adding it like Spl-KAN paper\n",
    "        self.wavelet_weights = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.wavelet_weights, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.weight1, a=math.sqrt(5))\n",
    "\n",
    "        # Base activation function #not used for this experiment\n",
    "        self.base_activation = nn.SiLU()\n",
    "\n",
    "        # Batch normalization\n",
    "        self.bn = nn.BatchNorm1d(out_features)\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x_expanded = x.unsqueeze(1)\n",
    "        else:\n",
    "            x_expanded = x\n",
    "\n",
    "        print(x_expanded.size())\n",
    "\n",
    "        translation_expanded = self.translation.unsqueeze(0).expand(x.size(0), -1, -1)\n",
    "        print(f'{translation_expanded.size()=}')\n",
    "        scale_expanded = self.scale.unsqueeze(0).expand(x.size(0), -1, -1)\n",
    "        print(f'{scale_expanded.size()=}')\n",
    "        x_scaled = (x_expanded - translation_expanded) / scale_expanded\n",
    "        print(f'{x_scaled.size()=}')\n",
    "\n",
    "        # Implementation of different wavelet types\n",
    "        if self.wavelet_type == 'mexican_hat':\n",
    "            term1 = ((x_scaled ** 2)-1)\n",
    "            term2 = torch.exp(-0.5 * x_scaled ** 2)\n",
    "            print(f'{term1.size()=}, {term2.size()=}')\n",
    "            wavelet = (2 / (math.sqrt(3) * math.pi**0.25)) * term1 * term2\n",
    "            wavelet_weighted = wavelet * self.wavelet_weights.unsqueeze(0).expand_as(wavelet)\n",
    "            print(f'{wavelet.size()=}, {wavelet_weighted.size()=}')\n",
    "            wavelet_output = wavelet_weighted.sum(dim=2)\n",
    "            print(f'{wavelet_output.size()=}')\n",
    "        elif self.wavelet_type == 'morlet':\n",
    "            omega0 = 5.0  # Central frequency\n",
    "            real = torch.cos(omega0 * x_scaled)\n",
    "            envelope = torch.exp(-0.5 * x_scaled ** 2)\n",
    "            wavelet = envelope * real\n",
    "            wavelet_weighted = wavelet * self.wavelet_weights.unsqueeze(0).expand_as(wavelet)\n",
    "            wavelet_output = wavelet_weighted.sum(dim=2)\n",
    "            \n",
    "        elif self.wavelet_type == 'dog':\n",
    "            # Implementing Derivative of Gaussian Wavelet \n",
    "            dog = -x_scaled * torch.exp(-0.5 * x_scaled ** 2)\n",
    "            wavelet = dog\n",
    "            wavelet_weighted = wavelet * self.wavelet_weights.unsqueeze(0).expand_as(wavelet)\n",
    "            wavelet_output = wavelet_weighted.sum(dim=2)\n",
    "        elif self.wavelet_type == 'meyer':\n",
    "            # Implement Meyer Wavelet here\n",
    "            # Constants for the Meyer wavelet transition boundaries\n",
    "            v = torch.abs(x_scaled)\n",
    "            pi = math.pi\n",
    "\n",
    "            def meyer_aux(v):\n",
    "                return torch.where(v <= 1/2,torch.ones_like(v),torch.where(v >= 1,torch.zeros_like(v),torch.cos(pi / 2 * nu(2 * v - 1))))\n",
    "\n",
    "            def nu(t):\n",
    "                return t**4 * (35 - 84*t + 70*t**2 - 20*t**3)\n",
    "            # Meyer wavelet calculation using the auxiliary function\n",
    "            wavelet = torch.sin(pi * v) * meyer_aux(v)\n",
    "            wavelet_weighted = wavelet * self.wavelet_weights.unsqueeze(0).expand_as(wavelet)\n",
    "            wavelet_output = wavelet_weighted.sum(dim=2)\n",
    "        elif self.wavelet_type == 'shannon':\n",
    "            # Windowing the sinc function to limit its support\n",
    "            pi = math.pi\n",
    "            sinc = torch.sinc(x_scaled / pi)  # sinc(x) = sin(pi*x) / (pi*x)\n",
    "\n",
    "            # Applying a Hamming window to limit the infinite support of the sinc function\n",
    "            window = torch.hamming_window(x_scaled.size(-1), periodic=False, dtype=x_scaled.dtype, device=x_scaled.device)\n",
    "            # Shannon wavelet is the product of the sinc function and the window\n",
    "            wavelet = sinc * window\n",
    "            wavelet_weighted = wavelet * self.wavelet_weights.unsqueeze(0).expand_as(wavelet)\n",
    "            wavelet_output = wavelet_weighted.sum(dim=2)\n",
    "            #You can try many more wavelet types ...\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported wavelet type\")\n",
    "\n",
    "        return wavelet_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        wavelet_output = self.wavelet_transform(x)\n",
    "        #You may like test the cases like Spl-KAN\n",
    "        #wav_output = F.linear(wavelet_output, self.weight)\n",
    "        #base_output = F.linear(self.base_activation(x), self.weight1)\n",
    "\n",
    "        base_output = F.linear(x, self.weight1)\n",
    "        combined_output =  wavelet_output #+ base_output \n",
    "\n",
    "        # Apply batch normalization\n",
    "        return self.bn(combined_output)\n",
    "\n",
    "class KAN(nn.Module):\n",
    "    def __init__(self, layers_hidden, wavelet_type='mexican_hat'):\n",
    "        super(KAN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for in_features, out_features in zip(layers_hidden[:-1], layers_hidden[1:]):\n",
    "            self.layers.append(KANLinear(in_features, out_features, wavelet_type))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 128])\n",
      "translation_expanded.size()=torch.Size([1000, 144, 128])\n",
      "scale_expanded.size()=torch.Size([1000, 144, 128])\n",
      "x_scaled.size()=torch.Size([1000, 144, 128])\n",
      "term1.size()=torch.Size([1000, 144, 128]), term2.size()=torch.Size([1000, 144, 128])\n",
      "wavelet.size()=torch.Size([1000, 144, 128]), wavelet_weighted.size()=torch.Size([1000, 144, 128])\n",
      "wavelet_output.size()=torch.Size([1000, 144])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9303,  0.4346, -1.1224,  ..., -0.4664,  1.1976,  0.9476],\n",
       "        [ 0.8187,  0.7688, -0.2611,  ..., -1.2191,  1.0781,  0.2735],\n",
       "        [ 0.2438,  0.5340, -2.0622,  ..., -0.5690, -1.8118,  0.7056],\n",
       "        ...,\n",
       "        [-0.7016, -0.3629, -1.8911,  ..., -0.7746, -1.1137,  0.0870],\n",
       "        [-2.0423,  0.6564,  1.9434,  ...,  0.3529,  1.7313, -0.1726],\n",
       "        [ 0.0924,  1.4126,  0.6934,  ...,  0.3420, -0.5840, -0.7927]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1000, 128)\n",
    "layer = KANLinear(128, 144)\n",
    "\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
